{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e822ebf6-49dc-465d-b7a9-6530d44fd466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", family=\"serif\", size=16)\n",
    "plt.rc(\"axes\", titlesize=\"medium\")\n",
    "plt.rc(\"text.latex\", preamble=r\"\\usepackage{amsmath}\")\n",
    "plt.rc(\"text\", usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3979737-fe56-4f6a-a34d-74813d8bfab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01menergyflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mef\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\u001b[43msample_name\u001b[49m: ef\u001b[38;5;241m.\u001b[39mzjets_delphes\u001b[38;5;241m.\u001b[39mload(sample_name, num_data\u001b[38;5;241m=\u001b[39mN_t\u001b[38;5;241m+\u001b[39mN_v,\n\u001b[1;32m      3\u001b[0m                                                cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,exclude_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticles\u001b[39m\u001b[38;5;124m'\u001b[39m])}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_name' is not defined"
     ]
    }
   ],
   "source": [
    "import energyflow as ef\n",
    "\n",
    "sample_name='Pythia26'\n",
    "N_t=1000000\n",
    "N_v=600000\n",
    "cache_dir=\"/global/cfs/cdirs/m3929/I2SB/\"\n",
    "json_path='JSON'\n",
    "\n",
    "datasets = {sample_name: ef.zjets_delphes.load(sample_name, num_data=N_t+N_v,\n",
    "                                               cache_dir=cache_dir,exclude_keys=['particles'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52984fd6-4bae-4c9d-b0dd-07bb4f79705b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['hard', 'reco']>\n",
      "(1000000, 6)\n",
      "(1000000, 6)\n"
     ]
    }
   ],
   "source": [
    "load_dir=\"/global/cfs/projectdirs/m3246/sdiefenbacher/Schroedinger_Bridge/SBUnfold_data/OmniFold_big/\"\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "\n",
    "\n",
    "file = 'OmniFold_train_small.h5'\n",
    "#file = 'OmniFold_train_large.h5'\n",
    "\n",
    "#frame = pd.read_hdf(load_dir + file, mode='r')\n",
    "f = h5.File(load_dir + file, 'r')\n",
    "\"jet mass\", \n",
    "\"jet width\", \n",
    "\"jet multiplicity\", \n",
    "\"jet soft drop mass\", \n",
    "\"jet groomed momentum fraction z_g\", \n",
    "\"jet N-subjettiness ratio tau_21\"\n",
    "\n",
    "print(f.keys())\n",
    "print(f['hard'][:].shape)\n",
    "print(f['reco'][:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb70964-9d87-440e-8bda-12f4f507da51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.ticker as mtick\n",
    "import json\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def SaveJson(save_file,data,base_folder='JSON'):\n",
    "    if not os.path.isdir(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "    \n",
    "    with open(os.path.join(base_folder,save_file),'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "    \n",
    "def LoadJson(file_name,base_folder='JSON'):\n",
    "    import json,yaml\n",
    "    JSONPATH = os.path.join(base_folder,file_name)\n",
    "    return yaml.safe_load(open(JSONPATH))\n",
    "\n",
    "\n",
    "def CalcPreprocessingComparison(data,fname,base_folder):\n",
    "    '''Apply data preprocessing'''\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    z = data.copy()\n",
    "    z4 = z[:, 4]\n",
    "    noise = np.random.rand(*z4.shape)/1000. * 3 + 0.097\n",
    "    z4 = np.where(z4 < 0.1, noise, z4)\n",
    "    z4 = np.log(z4)\n",
    "    shift = (np.max(z4) + np.min(z4))/2.\n",
    "    z4 = z4-shift\n",
    "    factor = max(np.max(z4), -1 * np.min(z4))*1.001\n",
    "    \n",
    "    data_dict['shift']=shift.tolist()\n",
    "    data_dict['factor']=factor.tolist()\n",
    "    SaveJson(fname,data_dict,base_folder)\n",
    "\n",
    "def ApplyPreprocessingComparison(data,fname,base_folder):\n",
    "    channels = 2\n",
    "    z = data.copy()\n",
    "    noise = np.random.rand(*z[:, channels].shape)-0.5\n",
    "    z[:, channels] = z[:,channels] + noise\n",
    "\n",
    "    data_dict = LoadJson(fname,base_folder)\n",
    "\n",
    "    z4 = z[:, 4]\n",
    "    noise = np.random.rand(*z4.shape)/1000. * 3 + 0.097\n",
    "    z4 = np.where(z4 < 0.1, noise, z4)\n",
    "    z4 = np.log(z4)\n",
    "    z4 = z4-data_dict['shift']\n",
    "    z4 = z4/data_dict['factor']\n",
    "    z4 = sp.special.erfinv(z4)\n",
    "    z[:, 4] = z4\n",
    "    \n",
    "    return z\n",
    "\n",
    "\n",
    "def ReversePreprocessingComparison(data,fname,base_folder):    \n",
    "    channels = 2\n",
    "    z = data.copy()\n",
    "    z[:, channels] = np.round(z[:, channels])    \n",
    "    \n",
    "    data_dict = LoadJson(fname,base_folder)\n",
    "    \n",
    "    z4 = z[:, 4]\n",
    "    z4 = sp.special.erf(z4)\n",
    "    z4 = z4*data_dict['factor']\n",
    "    z4 = z4+data_dict['shift']\n",
    "    z4 = np.exp(z4)\n",
    "    z4 = np.where(z4 < 0.1, 0, z4)\n",
    "    z[:, 4] = z4\n",
    "    \n",
    "    return z\n",
    "\n",
    "def CalcPreprocessing(data,fname,base_folder):\n",
    "    '''Apply data preprocessing'''\n",
    "    \n",
    "    data_dict = {}\n",
    "    mean = np.average(data,axis=0)\n",
    "    std = np.std(data,axis=0)\n",
    "    data_dict['mean']=mean.tolist()\n",
    "    data_dict['std']=std.tolist()\n",
    "    data_dict['min']=np.min(data,0).tolist()\n",
    "    data_dict['max']=np.max(data,0).tolist()    \n",
    "    \n",
    "    SaveJson(fname,data_dict,base_folder)\n",
    "\n",
    "\n",
    "\n",
    "def ApplyPreprocessing(data,fname,base_folder):\n",
    "    #CalcPreprocessing(data,fname,base_folder)    \n",
    "    data_dict = LoadJson(fname,base_folder)\n",
    "    \n",
    "    data = (np.ma.divide((data-data_dict['mean']),data_dict['std']).filled(0)).astype(np.float32)\n",
    "    #data = (np.ma.divide((data-data_dict['min']),np.array(data_dict['max']) - data_dict['min']).filled(0)).astype(np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def ReversePreprocessing(data,fname,base_folder):\n",
    "    data_dict = LoadJson(fname,base_folder)\n",
    "    #data = (np.array(data_dict['max']) - data_dict['min']) * data + data_dict['min']\n",
    "    data = data * data_dict['std'] + data_dict['mean']\n",
    "    data[:,2] = np.round(data[:,2]) #particle multiplicity should be an integer\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28dbb162-5b94-4a84-9969-7efb7da646c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.08579122, -0.9301205 , -0.17122631, -1.8736101 ,  0.4120006 ,\n",
       "          0.7104949 ],\n",
       "        [ 1.3231078 ,  0.6154586 ,  1.6004199 ,  0.8055421 , -0.54660356,\n",
       "         -0.5283266 ],\n",
       "        [-0.7696968 , -0.5213547 , -0.49022108, -0.64269024, -0.41413632,\n",
       "          0.84578836],\n",
       "        ...,\n",
       "        [ 0.28893548, -0.6812093 , -0.3551638 , -0.05711501, -1.4505641 ,\n",
       "          0.5985801 ],\n",
       "        [ 0.21505466,  0.2202359 ,  0.3231511 ,  1.0803062 , -1.2597023 ,\n",
       "         -1.9818573 ],\n",
       "        [-1.2847716 , -0.856341  , -1.2612385 ,  0.10978325, -1.8698372 ,\n",
       "          0.73945296]], dtype=float32),\n",
       " array([[-0.08500465, -0.8382267 , -0.09482869, -1.400729  ,  0.1283816 ,\n",
       "         -0.5303387 ],\n",
       "        [ 1.1511995 ,  0.18972191,  0.86756486,  0.8873127 , -1.2527363 ,\n",
       "         -0.00429419],\n",
       "        [-0.7645649 , -0.80731356, -0.6157459 , -0.59433836, -0.46263155,\n",
       "          1.6027604 ],\n",
       "        ...,\n",
       "        [-0.70639575, -0.8807829 , -0.39836696, -0.1628885 , -0.45459557,\n",
       "          0.9892267 ],\n",
       "        [-0.6189143 , -0.7334991 , -1.4560014 , -0.35723832, -1.0163281 ,\n",
       "         -0.1695185 ],\n",
       "        [-1.3369548 , -0.94720316, -1.2047    , -0.13469581, -1.1155789 ,\n",
       "          0.3333669 ]], dtype=float32),\n",
       " array([[ 0.30820414,  1.3173414 ,  0.25641194,  1.2242651 , -0.01065682,\n",
       "         -1.0417178 ],\n",
       "        [ 1.9311752 ,  0.57154393,  1.573297  , -0.32899824,  0.00878612,\n",
       "          1.0399268 ],\n",
       "        [-0.79059994, -0.8205596 , -0.7693679 ,  0.07430622, -0.03448831,\n",
       "          1.925238  ],\n",
       "        ...,\n",
       "        [-0.675953  , -0.56068045, -0.47887972, -0.4564735 , -0.6858834 ,\n",
       "          0.89182746],\n",
       "        [ 0.51380914, -0.68069315, -0.673436  , -0.6368178 ,  0.2719764 ,\n",
       "          1.3881817 ],\n",
       "        [ 1.6945544 ,  1.2488477 ,  1.8610376 ,  1.0826802 , -0.9977637 ,\n",
       "          0.45367855]], dtype=float32),\n",
       " array([[ 0.21004978,  1.2540038 ,  0.2115479 ,  0.9170585 ,  0.27376333,\n",
       "         -0.46971083],\n",
       "        [ 1.345329  ,  0.41291937,  1.1433817 ,  0.45536685, -1.2188971 ,\n",
       "          0.6933216 ],\n",
       "        [-1.0019232 , -0.89614356, -0.75009763,  0.18787058, -0.84925294,\n",
       "         -0.11081203],\n",
       "        ...,\n",
       "        [-0.5540651 , -0.7096169 ,  0.04439879, -0.49143323, -0.7985709 ,\n",
       "          1.641373  ],\n",
       "        [-0.38505772, -0.75885475, -0.5038378 , -0.43712226, -0.5225549 ,\n",
       "          1.3580195 ],\n",
       "        [ 2.0281594 ,  1.4902215 ,  2.427056  ,  0.8807313 , -0.6955081 ,\n",
       "          1.1957506 ]], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DataLoaderComparison(sample_name,\n",
    "               N_t=1000000,N_v=600000,\n",
    "               cache_dir=\"/global/cfs/cdirs/m3929/I2SB/\",json_path='JSON', \n",
    "               test_name='OmniFold_test.h5',):\n",
    "    \n",
    "    if sample_name=='OmniFold_train_small.h5':\n",
    "        json_name='_comparison_small'\n",
    "        \n",
    "        \n",
    "    if sample_name=='OmniFold_train_large.h5':\n",
    "        json_name='_comparison_large'\n",
    "\n",
    "    #frame = pd.read_hdf(load_dir + file, mode='r')\n",
    "    f_train = h5.File(cache_dir + sample_name, 'r')\n",
    "    gen_features_train = f_train['hard'][:]\n",
    "    sim_features_train = f_train['reco'][:]\n",
    "    \n",
    "    # ln rho\n",
    "    #gen_features[:,3] = 2*np.ma.log(gen_features[:,3]).filled(0)\n",
    "    #sim_features[:,3] = 2*np.ma.log(sim_features[:,3]).filled(0)\n",
    "    # tau2\n",
    "    #gen_features[:,5] = gen_features[:,5]/(10**-50 + gen_features[:,1])\n",
    "    #sim_features[:,5] = sim_features[:,5]/(10**-50 + sim_features[:,1])\n",
    "    \n",
    "    CalcPreprocessingComparison(gen_features_train,'gen_features1' + json_name + '.json',json_path)\n",
    "    CalcPreprocessingComparison(sim_features_train,'sim_features1' + json_name + '.json',json_path)\n",
    "\n",
    "    \n",
    "    gen_features_train = ApplyPreprocessingComparison(gen_features_train,'gen_features1' + json_name + '.json',json_path)\n",
    "    sim_features_train = ApplyPreprocessingComparison(sim_features_train,'sim_features1' + json_name + '.json',json_path)\n",
    "    \n",
    "    print(np.mean(gen_features_train==gen_features_train))\n",
    "    print(np.mean(sim_features_train==sim_features_train))\n",
    "    \n",
    "    CalcPreprocessing(gen_features_train,'gen_features2' + json_name + '.json',json_path)\n",
    "    CalcPreprocessing(sim_features_train,'sim_features2' + json_name + '.json',json_path)\n",
    "\n",
    "    gen_features_train = ApplyPreprocessing(gen_features_train,'gen_features2' + json_name + '.json',json_path)\n",
    "    sim_features_train = ApplyPreprocessing(sim_features_train,'sim_features2' + json_name + '.json',json_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    f_test = h5.File(cache_dir + test_name, 'r')\n",
    "    gen_features_test = f_test['hard'][:]\n",
    "    sim_features_test = f_test['reco'][:]\n",
    "    \n",
    "    gen_features_test = ApplyPreprocessingComparison(gen_features_test,'gen_features1' + json_name + '.json',json_path)\n",
    "    sim_features_test = ApplyPreprocessingComparison(sim_features_test,'sim_features1' + json_name + '.json',json_path)\n",
    "    \n",
    "    gen_features_test = ApplyPreprocessing(gen_features_test,'gen_features2' + json_name + '.json',json_path)\n",
    "    sim_features_test = ApplyPreprocessing(sim_features_test,'sim_features2' + json_name + '.json',json_path)\n",
    "\n",
    "    train_gen = gen_features_train\n",
    "    train_sim = sim_features_train\n",
    "    \n",
    "    test_gen = gen_features_test\n",
    "    test_sim = sim_features_test\n",
    "\n",
    "    return train_gen, train_sim, test_gen, test_sim\n",
    "\n",
    "\n",
    "DataLoaderComparison(sample_name='OmniFold_train_small.h5',\n",
    "                   N_t=1000000,N_v=600000,\n",
    "                   cache_dir=\"/global/cfs/projectdirs/m3246/sdiefenbacher/Schroedinger_Bridge/SBUnfold_data/OmniFold_big/\",\n",
    "                   json_path='JSON')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7209bed-4585-45d8-bf62-7754d9e466bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def UniformNoisePreprocessing(self, x: torch.Tensor, rev: bool) -> torch.Tensor:\n",
    "    if rev:\n",
    "        z = x.clone()\n",
    "        z[:, self.channels] = torch.round(z[:, self.channels])\n",
    "    else:\n",
    "        z = x.clone()\n",
    "        noise = torch.rand_like(z[:, self.channels])-0.5\n",
    "        z[:, self.channels] = z[:, self.channels] + noise\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "132fbd3d-f013-4cf2-9ed1-6fb43a2e0feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(self, x: torch.Tensor, rev: bool) -> torch.Tensor:\n",
    "    if rev:\n",
    "        z = x.clone()\n",
    "        z4 = z[:, 4]\n",
    "        z4 = torch.erf(z4)\n",
    "        z4 = z4*self.factor\n",
    "        z4 = z4+self.shift\n",
    "        z4 = z4.exp()\n",
    "        z4 = torch.where(z4 < 0.1, 0, z4)\n",
    "        z[:, 4] = z4\n",
    "    else:\n",
    "        z = x.clone()\n",
    "        z4 = z[:, 4]\n",
    "        noise = torch.rand(size=z4.shape, device=x.device)/1000. * 3 + 0.097\n",
    "        z4 = torch.where(z4 < 0.1, noise, z4)\n",
    "        z4 = z4.log()\n",
    "        self.shift = (z4.max() + z4.min())/2.\n",
    "        z4 = z4-self.shift\n",
    "        self.factor = max(z4.max(), -1 * z4.min())*1.001\n",
    "        z4 = z4/self.factor\n",
    "        z4 = torch.erfinv(z4)\n",
    "        z[:, 4] = z4\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07878b04-c57b-4415-b560-129f719950b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDiefenbacher_pytorch201",
   "language": "python",
   "name": "sdiefenbacher_pytorch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
